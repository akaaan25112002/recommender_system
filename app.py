import streamlit as st
import pandas as pd
import numpy as np
from data_loader import load_processed_data, load_ratings
from recommender import recommend_for_user_gensim, get_svd_recommendations
from utils import clean_text_row, stop_words
from underthesea import word_tokenize
import base64
import unicodedata
import sys
import os

sys.path.append(os.path.abspath(os.path.dirname(__file__)))

# ===== Helper Functions =====

def image_to_base64(image_path):
    try:
        with open(image_path, "rb") as image_file:
            encoded = base64.b64encode(image_file.read()).decode()
        return f"data:image/png;base64,{encoded}"
    except:
        return ""

def preprocess_text(text):
    tokens = word_tokenize(text, format="text").split()
    return clean_text_row(tokens, stop_words)

def remove_accents(text):
    return ''.join(c for c in unicodedata.normalize('NFD', text)
                   if unicodedata.category(c) != 'Mn')

# ===== Load Data =====

data, dictionary, tfidf, index = load_processed_data()
ratings = load_ratings()
products = data.dropna(subset=["Content", "product_name"]).copy()

# T·∫°o th√™m c·ªôt kh√¥ng d·∫•u ƒë·ªÉ t√¨m ki·∫øm
products['product_name_clean'] = products['product_name'].apply(lambda x: remove_accents(str(x).lower()))

# ===== Sidebar =====
with st.sidebar:
    st.title("üîç Shopee Recommender")
    st.markdown("### ‚ÑπÔ∏è Th√¥ng tin m√¥ h√¨nh")
    st.markdown("""
    - **Ph∆∞∆°ng ph√°p**: Content-Based & Collaborative Filtering  
    - **M√¥ h√¨nh**: Gensim TF-IDF & Surprise SVD  
    - **Ngu·ªìn d·ªØ li·ªáu**: Shopee Products & Ratings  
    - **S·ªë l∆∞·ª£ng s·∫£n ph·∫©m**: 49,663  
    - **T∆∞∆°ng t√°c ng∆∞·ªùi d√πng**: 990,000+
    """)
    st.markdown("---")
    selected_tab = st.radio("Ch·ªçn ch·ª©c nƒÉng", ["S·∫£n ph·∫©m n·ªïi b·∫≠t", "T√¨m ki·∫øm s·∫£n ph·∫©m", "G·ª£i √Ω cho b·∫°n"])
    st.markdown("Made with ‚ù§Ô∏è by Anh Khoa & Thi√™n B·∫£o")

# ===== Default Image =====
default_image_path = "Data/No_image_available.svg.png"
default_image_url = image_to_base64(default_image_path)

# ===== Tab 1: S·∫£n ph·∫©m n·ªïi b·∫≠t =====
if selected_tab == "S·∫£n ph·∫©m n·ªïi b·∫≠t":
    st.header("üî• S·∫£n ph·∫©m n·ªïi b·∫≠t theo danh m·ª•c")
    sub_categories = ['T·∫•t c·∫£'] + products['sub_category'].dropna().unique().tolist()
    selected_sub_category = st.selectbox("Ch·ªçn danh m·ª•c con", options=sub_categories)

    if selected_sub_category == "T·∫•t c·∫£":
        top_items = products.sort_values(by='rating', ascending=False).head(15)
    else:
        top_items = products[products['sub_category'] == selected_sub_category].sort_values(by='rating', ascending=False).head(15)

    for _, row in top_items.iterrows():
        image_url = row.image if pd.notna(row.image) and str(row.image).startswith("http") else default_image_url
        st.image(image_url, width=180)
        st.markdown(f"**üõçÔ∏è {row.product_name}**")
        st.markdown(f"‚≠ê {row.rating} | üíµ {int(row.price):,}")
        st.markdown("---")

# ===== Tab 2: T√¨m ki·∫øm s·∫£n ph·∫©m =====
elif selected_tab == "T√¨m ki·∫øm s·∫£n ph·∫©m":
    st.header("üîé T√¨m ki·∫øm s·∫£n ph·∫©m")
    search_input = st.text_input("Nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm:")
    selected_sub = st.selectbox("Ch·ªçn danh m·ª•c con", options=["T·∫•t c·∫£"] + list(products['sub_category'].dropna().unique()))

    if search_input:
        query_clean = remove_accents(search_input.lower())
        matched = products[products['product_name_clean'].str.contains(query_clean)]

        if selected_sub != "T·∫•t c·∫£":
            matched = matched[matched['sub_category'] == selected_sub]

        if matched.empty:
            st.warning("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p.")
        else:
            chosen = matched.iloc[0]
            st.success(f"üéØ G·ª£i √Ω c√°c s·∫£n ph·∫©m t∆∞∆°ng t·ª± v·ªõi: {chosen.product_name}")
            query_doc = dictionary.doc2bow(preprocess_text(chosen.Content))
            sims = index[tfidf[query_doc]]
            top_indices = np.argsort(sims)[::-1][1:11]

            for idx in top_indices:
                product = products.iloc[idx]
                image_url = product.image if pd.notna(product.image) and str(product.image).startswith("http") else default_image_url
                st.image(image_url, width=180)
                st.markdown(f"**üõçÔ∏è {product.product_name}**")
                st.markdown(f"‚≠ê {product.rating} | üíµ {int(product.price):,}")
                st.markdown("---")

# ===== Tab 3: G·ª£i √Ω cho b·∫°n =====
elif selected_tab == "G·ª£i √Ω cho b·∫°n":
    st.header("üéÅ G·ª£i √Ω s·∫£n ph·∫©m cho b·∫°n")
    user_id = st.text_input("Nh·∫≠p ID ng∆∞·ªùi d√πng:")
    method = st.radio("Ch·ªçn ph∆∞∆°ng ph√°p g·ª£i √Ω", ["SVD (Collaborative)", "Gensim (Content-Based)"])

    if user_id:
        with st.spinner("ƒêang t·∫°o g·ª£i √Ω..."):
            if method == "SVD (Collaborative)":
                recs = get_svd_recommendations(user_id)
            else:
                recs = recommend_for_user_gensim(user_id)

        if isinstance(recs, pd.DataFrame):
            for _, row in recs.iterrows():
                image_url = row.image if pd.notna(row.image) and str(row.image).startswith("http") else default_image_url
                st.image(image_url, width=180)
                st.markdown(f"**üõçÔ∏è {row.product_name}**")
                st.markdown(f"‚≠ê {row.rating} | üíµ {int(row.price):,}")
                if "predicted_rating" in row:
                    st.markdown(f"üìä D·ª± ƒëo√°n ƒë√°nh gi√°: **{row.predicted_rating:.2f}**")
                st.markdown("---")
        elif isinstance(recs, str):
            st.warning(recs)
        else:
            st.error("Kh√¥ng th·ªÉ t·∫°o g·ª£i √Ω. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ho·∫∑c th·ª≠ l·∫°i sau.")